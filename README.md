# Toxic Language Detection (Logistic Regression Model)

## üìå Project Overview
This project implements a **Logistic Regression model** to detect toxic language in text.  
It serves as the **prototype stage** of a larger multilingual toxicity detection system, demonstrating the feasibility of machine learning for identifying offensive or harmful content.  
CSV File: https://www.kaggle.com/competitions/jigsaw-multilingual-toxic-comment-classification
---

## ‚öôÔ∏è Tech Stack
- **Language:** Python  
- **Libraries:** scikit-learn, pandas, numpy, nltk  
- **Environment:** Jupyter Notebook / Python script  

---

## üöÄ How to Run

1. **Clone the repo**
   ```bash
   git clone https://github.com/your-username/toxic-language-logistic-regression.git
   cd toxic-language-logistic-regression
